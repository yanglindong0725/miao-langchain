import { ChatOpenAI } from "@langchain/openai";
import {
  ChatPromptTemplate,
  FewShotChatMessagePromptTemplate,
} from "@langchain/core/prompts";
import { NextResponse } from "next/server";
import { ChainHandler } from "../types";

/**
 * Few-shot Learning Handler
 * é€šè¿‡å°‘é‡ç¤ºä¾‹æ•™ä¼šæ¨¡å‹å®Œæˆä»»åŠ¡
 */
export const fewshotHandler: ChainHandler = {
  handle: async (input: string, model: ChatOpenAI) => {
    // Few-shot å­¦ä¹ ç¤ºä¾‹
    const examples = [
      { input: "å¼€å¿ƒ", output: "ğŸ˜Š" },
      { input: "éš¾è¿‡", output: "ğŸ˜¢" },
    ];

    const examplePrompt = ChatPromptTemplate.fromMessages([
      ["human", "{input}"],
      ["ai", "{output}"],
    ]);

    const fewShotPrompt = new FewShotChatMessagePromptTemplate({
      examplePrompt,
      examples,
      inputVariables: ["input"],
    });

    const finalPrompt = ChatPromptTemplate.fromMessages([
      ["system", "å°†æƒ…ç»ªè¯è½¬æ¢ä¸ºå¯¹åº”çš„è¡¨æƒ…ç¬¦å·"],
      fewShotPrompt as any,
      ["human", "{input}"],
    ]);

    const chain = finalPrompt.pipe(model);
    const response = await chain.invoke({ input });

    return NextResponse.json({
      response: response.content,
    });
  },
};

